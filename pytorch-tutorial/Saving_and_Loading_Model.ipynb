{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import things\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform function\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=(0.5,0.5,0.5,0.5), std=(0.5,0.5,0.5,0.5))])\n",
    "# Downlaod and load the training set\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "# Download and load the test set\n",
    "testset = datasets.FashionMNIST('F_MNIST_data', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1179d26d8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "helper.imshow(images[0,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2.. Training Loss: 1.581 Test Loss: 0.880 Accuracy: 0.669\n",
      "Epoch: 1/2.. Training Loss: 0.961 Test Loss: 0.696 Accuracy: 0.745\n",
      "Epoch: 1/2.. Training Loss: 0.818 Test Loss: 0.644 Accuracy: 0.753\n",
      "Epoch: 1/2.. Training Loss: 0.782 Test Loss: 0.617 Accuracy: 0.762\n",
      "Epoch: 1/2.. Training Loss: 0.703 Test Loss: 0.584 Accuracy: 0.780\n",
      "Epoch: 1/2.. Training Loss: 0.716 Test Loss: 0.565 Accuracy: 0.784\n",
      "Epoch: 1/2.. Training Loss: 0.660 Test Loss: 0.561 Accuracy: 0.790\n",
      "Epoch: 1/2.. Training Loss: 0.618 Test Loss: 0.548 Accuracy: 0.791\n",
      "Epoch: 1/2.. Training Loss: 0.650 Test Loss: 0.540 Accuracy: 0.804\n",
      "Epoch: 1/2.. Training Loss: 0.609 Test Loss: 0.519 Accuracy: 0.808\n",
      "Epoch: 1/2.. Training Loss: 0.580 Test Loss: 0.525 Accuracy: 0.803\n",
      "Epoch: 1/2.. Training Loss: 0.618 Test Loss: 0.528 Accuracy: 0.810\n",
      "Epoch: 1/2.. Training Loss: 0.594 Test Loss: 0.500 Accuracy: 0.820\n",
      "Epoch: 1/2.. Training Loss: 0.600 Test Loss: 0.534 Accuracy: 0.802\n",
      "Epoch: 1/2.. Training Loss: 0.613 Test Loss: 0.486 Accuracy: 0.817\n",
      "Epoch: 1/2.. Training Loss: 0.570 Test Loss: 0.513 Accuracy: 0.811\n",
      "Epoch: 1/2.. Training Loss: 0.546 Test Loss: 0.489 Accuracy: 0.825\n",
      "Epoch: 1/2.. Training Loss: 0.591 Test Loss: 0.512 Accuracy: 0.810\n",
      "Epoch: 2/2.. Training Loss: 0.557 Test Loss: 0.487 Accuracy: 0.818\n",
      "Epoch: 2/2.. Training Loss: 0.537 Test Loss: 0.499 Accuracy: 0.818\n",
      "Epoch: 2/2.. Training Loss: 0.583 Test Loss: 0.472 Accuracy: 0.824\n",
      "Epoch: 2/2.. Training Loss: 0.537 Test Loss: 0.494 Accuracy: 0.825\n",
      "Epoch: 2/2.. Training Loss: 0.521 Test Loss: 0.470 Accuracy: 0.826\n",
      "Epoch: 2/2.. Training Loss: 0.585 Test Loss: 0.480 Accuracy: 0.826\n",
      "Epoch: 2/2.. Training Loss: 0.536 Test Loss: 0.472 Accuracy: 0.828\n",
      "Epoch: 2/2.. Training Loss: 0.556 Test Loss: 0.466 Accuracy: 0.836\n",
      "Epoch: 2/2.. Training Loss: 0.518 Test Loss: 0.470 Accuracy: 0.825\n",
      "Epoch: 2/2.. Training Loss: 0.553 Test Loss: 0.476 Accuracy: 0.829\n",
      "Epoch: 2/2.. Training Loss: 0.512 Test Loss: 0.472 Accuracy: 0.822\n",
      "Epoch: 2/2.. Training Loss: 0.532 Test Loss: 0.457 Accuracy: 0.835\n",
      "Epoch: 2/2.. Training Loss: 0.537 Test Loss: 0.459 Accuracy: 0.827\n",
      "Epoch: 2/2.. Training Loss: 0.539 Test Loss: 0.458 Accuracy: 0.837\n",
      "Epoch: 2/2.. Training Loss: 0.525 Test Loss: 0.470 Accuracy: 0.830\n",
      "Epoch: 2/2.. Training Loss: 0.517 Test Loss: 0.451 Accuracy: 0.837\n",
      "Epoch: 2/2.. Training Loss: 0.510 Test Loss: 0.443 Accuracy: 0.840\n",
      "Epoch: 2/2.. Training Loss: 0.513 Test Loss: 0.437 Accuracy: 0.841\n",
      "Epoch: 2/2.. Training Loss: 0.506 Test Loss: 0.447 Accuracy: 0.839\n"
     ]
    }
   ],
   "source": [
    "NeuralNet.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model: \n",
      "\n",
      "  Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      "  odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print('The model: \\n\\n ', model, '\\n')\n",
    "print('The state dict keys: \\n\\n ', model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the simplest thing to save the state dict is using `torch.save`, e.g. we can save it to a file `checkpoint.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can also load the state dict with `torch.load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('./checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to load it to the model, we can use `model.load_state_dict(state_dict)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But, what if the model we created doesn't have exactly the same architecture? Then, it will fail to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param of torch.Size([400, 784]) from checkpoint, where the shape is torch.Size([512, 784]) in current model.\n\tsize mismatch for hidden_layers.0.bias: copying a param of torch.Size([400]) from checkpoint, where the shape is torch.Size([512]) in current model.\n\tsize mismatch for hidden_layers.1.weight: copying a param of torch.Size([200, 400]) from checkpoint, where the shape is torch.Size([256, 512]) in current model.\n\tsize mismatch for hidden_layers.1.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([256]) in current model.\n\tsize mismatch for hidden_layers.2.weight: copying a param of torch.Size([100, 200]) from checkpoint, where the shape is torch.Size([128, 256]) in current model.\n\tsize mismatch for hidden_layers.2.bias: copying a param of torch.Size([100]) from checkpoint, where the shape is torch.Size([128]) in current model.\n\tsize mismatch for output.weight: copying a param of torch.Size([10, 100]) from checkpoint, where the shape is torch.Size([10, 128]) in current model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-29c8fe0f87a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# this will throw an error because the tensor sizes are wrong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/100DaysOfMLCode/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 719\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param of torch.Size([400, 784]) from checkpoint, where the shape is torch.Size([512, 784]) in current model.\n\tsize mismatch for hidden_layers.0.bias: copying a param of torch.Size([400]) from checkpoint, where the shape is torch.Size([512]) in current model.\n\tsize mismatch for hidden_layers.1.weight: copying a param of torch.Size([200, 400]) from checkpoint, where the shape is torch.Size([256, 512]) in current model.\n\tsize mismatch for hidden_layers.1.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([256]) in current model.\n\tsize mismatch for hidden_layers.2.weight: copying a param of torch.Size([100, 200]) from checkpoint, where the shape is torch.Size([128, 256]) in current model.\n\tsize mismatch for hidden_layers.2.bias: copying a param of torch.Size([100]) from checkpoint, where the shape is torch.Size([128]) in current model.\n\tsize mismatch for output.weight: copying a param of torch.Size([10, 100]) from checkpoint, where the shape is torch.Size([10, 128]) in current model."
     ]
    }
   ],
   "source": [
    "model = NeuralNet.Network(784, 10, [400, 200, 100])\n",
    "# this will throw an error because the tensor sizes are wrong\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This means that, we need to rebuild the model exactly as it was when trained. Hence, __information about the model architectures need to be saved in the `checkpoint`, along with `state_dict`__.\n",
    "\n",
    "We can do this by defining a dictionary that takes all information we need above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have save all the information in `checkpoint.pth`, we can even build a function to load checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path):\n",
    "    'load a checkpoint of model'\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model = NeuralNet.Network(checkpoint['input_size'],\n",
    "                              checkpoint['output_size'],\n",
    "                              checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('./checkpoint.pth')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
